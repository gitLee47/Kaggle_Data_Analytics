{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encoding trial\n",
    "#v_0.1\n",
    "\n",
    "import pandas \n",
    "train_data = pandas.read_csv(\"C:/Study/kaggle_Pro/train.csv\") \n",
    "\n",
    "#Read test dataset\n",
    "test_data = pandas.read_csv(\"C:/Study/kaggle_Pro/test.csv\")\n",
    "#Save the id's for submission file\n",
    "ID = test_data['id']\n",
    "#Drop unnecessary columns\n",
    "test_data.drop('id',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the first column 'id' since it just has serial numbers. Not useful in the prediction process.\n",
    "train_data = train_data.iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "#range of features considered\n",
    "split = 116 \n",
    "\n",
    "#number of features considered\n",
    "size = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318L, 1176L)\n"
     ]
    }
   ],
   "source": [
    "#Use one hot encoding for categories feature\n",
    "import pandas\n",
    "\n",
    "#Variable to hold the list of variables for an attribute in the train and test data\n",
    "labels = []\n",
    "cols = train_data.columns\n",
    "\n",
    "for i in range(0,split):\n",
    "    train = train_data[cols[i]].unique()\n",
    "    test = test_data[cols[i]].unique()\n",
    "    labels.append(list(set(train) | set(test)))    \n",
    "\n",
    "del test_data\n",
    "\n",
    "#Import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#One hot encode all categorical attributes\n",
    "cats = []\n",
    "for i in range(0, split):\n",
    "    #Label encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels[i])\n",
    "    feature = label_encoder.transform(train_data.iloc[:,i])\n",
    "    feature = feature.reshape(train_data.shape[0], 1)\n",
    "    #One hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labels[i]))\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    cats.append(feature)\n",
    "\n",
    "encoded_cats = numpy.column_stack(cats)\n",
    "\n",
    "# Print the shape of the encoded data\n",
    "print(encoded_cats.shape)\n",
    "\n",
    "#Concatenate encoded attributes with continuous attributes\n",
    "dataset_encoded = numpy.concatenate((encoded_cats,train_data.iloc[:,split:].values),axis=1)\n",
    "del cats\n",
    "del feature\n",
    "del train_data\n",
    "del encoded_cats\n",
    "#print(dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\AppData\\Roaming\\Python\\Python27\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#get the number of rows and columns\n",
    "r, c = dataset_encoded.shape\n",
    "\n",
    "#create an array which has indexes of columns\n",
    "i_cols = []\n",
    "for i in range(0,c-1):\n",
    "    i_cols.append(i)\n",
    "\n",
    "#Y is the target column, X has the rest\n",
    "X = dataset_encoded[:,0:(c-1)]\n",
    "Y = dataset_encoded[:,(c-1)]\n",
    "del dataset_encoded\n",
    "\n",
    "#Validation chunk size\n",
    "val_size = 0.1\n",
    "\n",
    "#Use a common seed in all experiments so that same chunk is used for validation\n",
    "seed = 0\n",
    "\n",
    "#Split the data into chunks\n",
    "from sklearn import cross_validation\n",
    "X_train, X_val, Y_train, Y_val = cross_validation.train_test_split(X, Y, test_size=val_size, random_state=seed)\n",
    "del X\n",
    "del Y\n",
    "\n",
    "#All features\n",
    "X_all = []\n",
    "#we can set different combinations of features here for testing\n",
    "\n",
    "#List of combinations\n",
    "comb = []\n",
    "\n",
    "#Dictionary to store the MAE for all algorithms \n",
    "mae = []\n",
    "\n",
    "#Scoring parameter\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#Add this version of X to the list \n",
    "n = \"All\"\n",
    "X_all.append([n, i_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
